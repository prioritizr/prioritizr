---
title: "Solver Benchmarks"
output:
  rmarkdown::html_vignette:
    toc: true
    fig_caption: true
    self_contained: yes
fontsize: 11pt
documentclass: article
bibliography: references.bib
csl: reference-style.csl
vignette: >
  %\VignetteIndexEntry{Solver benchmarks}
  %\VignetteEngine{knitr::rmarkdown_notangle}
---

```{r, include = FALSE}
w <- 7
h <- 4
is_check <- ("CheckExEnv" %in% search()) || any(c("_R_CHECK_TIMINGS_",
             "_R_CHECK_LICENSE_") %in% names(Sys.getenv()))
knitr::opts_chunk$set(fig.align = "center", eval = !is_check,
                      fig.width = w, fig.height = h)
```

```{r, include = FALSE}
devtools::load_all()
```

# Introduction

TODO.

# Methods

TODO.

To start off, we will load some packages to help download the benchmark results and visualize them.

```{r "load packages", message = FALSE}
# load packages
library(prioritizr)
library(piggyback)
library(ggplot2)
library(tidyverse)
```

Next, download the benchmark results and load them into our session.

```{r "import results", message = FALSE}
# download data to temporary folder
pb_download(
  file = c("solutions.zip", "results.rda"),
  repo = "prioritizr/benchmark", dest = tempdir(), tag = "latest",
  show_progress = FALSE)

# load benchmark results
load(file.path(tempdir(), "results.rda"))

# load benchmark solutions
unzip(file.path(tempdir(), "solutions.zip"), exdir = tempdir())
solution_paths <-
  file.path(tempdir(), "solutions", paste0(benchmark_results$id, ".tif"))
solution_raster_data <- lapply(solution_paths, raster)
```
```{r "setup figures", message = FALSE}
planning_units <- unique(benchmark_results$number_of_planning_units)
boundary_penalty <- unique(benchmark_results$boundary_penalty)
all_solvers <- unique(benchmark_results$solver)

benchmark_plot <- function(pus = NULL, bp = NULL, obj = NULL,
                           sol = NULL, txt = NULL){
  
  benchmark_results_red <- benchmark_results %>%
    filter(objective == obj,
           solver %in% sol)
    ggplot(benchmark_results_red %>%
           filter(number_of_planning_units == pus, 
                  boundary_penalty == bp), 
         aes(x = relative_target * 100, y = run_time, color = solver)) +
  geom_line(aes(color=solver))+
  geom_point(aes(color=solver)) +
  labs(title = paste(txt, 
                     "72 features,",
                     pus, "planning units,",
                     bp, "boundary penalty.",
                     sep = " "),
       x = "Target",
       y = "Run time [seconds]")
}

```

# Results


We can now inspect the benchmark results. The `benchmark_results` table contains information for each benchmark run (e.g. run time), and the `solution_raster_data` contains the solutions generated for each benchmark run.

```{r "preview results"}
# preview results
print(benchmark_results)
```


  
Lets now generate a plot that shows average run times per solver. You can see
that average run times for CBC, CPLEX and Gurobi are consistently low and 
don't differ much from each other. lpsymphony and Rsymphony, which both use 
the SYMPHONY solver, take longer on average and with more complex problems,
the time difference between them and the other solvers is substantial.

```{r "plot average run times"}
# make plot
p0 <-
  ggplot(benchmark_results, aes(x = solver, y = run_time)) +
  geom_boxplot()

# render plot
print(p0)
```
  
## Minimum set benchmark results

Now, lets investigate the solver behavior in more detail.
Let's start with the smallest problem size we've benchmarked.  
All benchmark scenarios have 72 features.  
This problem has only `r planning_units[1]` planning units. 
You can see that all solvers solve the problem in a comparable amount of time
across all targets investigated. Only the CBC solver takes a little bit longer
then the other ones for the 10% target scenario, but the difference in seconds
is really only ~0.6. 

```{r "time for pu's 1"}
# make plot
p1 <- benchmark_plot(pus = planning_units[1],
                     bp = boundary_penalty[1],
                     obj = "add_min_set_objective",
                     sol = all_solvers,
                     txt = "Minimum set problem,")

# render plot
print(p1)
```
  
Next, lets look at the results for a more realistic problem with 
`r planning_units[2]` planning units and see how the timing of the different solvers used
compares.

```{r "time for pu's 2"}
# make plot
p2 <- benchmark_plot(pus = planning_units[2],
                     bp = boundary_penalty[1],
                     obj = "add_min_set_objective",
                     sol = all_solvers,
                     txt = "Minimum set problem,")
                     

# render plot
print(p2)
```
  
Next, we will look at a medium sized problem with `r planning_units[3]` planning units. Now
we really start to see the difference between SYMPHONY and the other solvers. 

```{r "time for pu's 3"}
# make plot
p3 <- benchmark_plot(pus = planning_units[3],
                     bp = boundary_penalty[1],
                     obj = "add_min_set_objective",
                     sol = all_solvers,
                     txt = "Minimum set problem,")                     

# render plot
print(p3)
```
  
Finally, lets look at timing comparisons for a large problem with `r planning_units[4]` 
planning units. The SYMPHONY solver is really struggling to find solutions now.

```{r "time for pu's 4"}
# make plot
p4 <- benchmark_plot(pus = planning_units[4],
                     bp = boundary_penalty[1],
                     obj = "add_min_set_objective",
                     sol = all_solvers,
                     txt = "Minimum set problem,")                     

# render plot
print(p4)
```
  
To get a better sense of how the faster solvers (CBC, CPLEX, Gurobi) compare for
this problem size, lets just look at those 3 solvers in the next plot.

```{r "time for pu's 4 fast only"}
# make plot
p5 <- benchmark_plot(pus = planning_units[4],
                     bp = boundary_penalty[1],
                     obj = "add_min_set_objective",
                     sol = c("add_cbc_solver", "add_cplex_solver", 
                             "add_gurobi_solver"),
                     txt = "Minimum set problem,") 

# render plot
print(p5)
```


## Minimum set benchmark results including low boundary penalty

Now lets at the same problem types, but this time with a `boundary_penalty` 
parameter added to the problem formulation.
  
Let's start again with the smallest problem size we've benchmarked.  
This problem has only `r planning_units[1]` planning units. 

```{r "time for pu's 1 and boundary penalty"}
# make plot
p6 <- benchmark_plot(pus = planning_units[1],
                     bp = boundary_penalty[2],
                     obj = "add_min_set_objective",
                     sol = all_solvers,
                     txt = "Minimum set problem,") 

# render plot
print(p6)
```
  
Next, lets look at the results for a more realistic problem with 
`r planning_units[2]` planning units and see how the timing of the different solvers used
compares.

```{r "time for pu's 2 and boundary penalty"}
# make plot
p7 <- benchmark_plot(pus = planning_units[2],
                     bp = boundary_penalty[2],
                     obj = "add_min_set_objective",
                     sol = all_solvers,
                     txt = "Minimum set problem,") 

# render plot
print(p7)
```
  
Next, we will look at a medium sized problem with `r planning_units[3]` planning units. Now
we really start to see the difference between SYMPHONY and the other solvers.

```{r "time for pu's 3 and boundary penalty"}
# make plot
p8 <- benchmark_plot(pus = planning_units[3],
                     bp = boundary_penalty[2],
                     obj = "add_min_set_objective",
                     sol = all_solvers,
                     txt = "Minimum set problem,") 

# render plot
print(p8)
```
  
Finally, lets look at timing comparisons for a large problem with `r planning_units[4]` 
planning units. You can see that the benchmark times vary greatly for the 
SYMPHONY solver.

```{r "time for pu's 4 and boundary penalty"}
# make plot
p9 <- benchmark_plot(pus = planning_units[4],
                     bp = boundary_penalty[2],
                     obj = "add_min_set_objective",
                     sol = all_solvers,
                     txt = "Minimum set problem,") 

# render plot
print(p9)
```
   
To get a better sense of how the more consistent solvers (CBC, CPLEX, Gurobi) 
compare for this problem size, lets just look at those 3 solvers in the next 
plot.

```{r "time for pu's 4 and boundary penalty fast"}
# make plot
p10 <- benchmark_plot(pus = planning_units[4],
                     bp = boundary_penalty[2],
                     obj = "add_min_set_objective",
                     sol = c("add_cbc_solver", "add_cplex_solver", 
                             "add_gurobi_solver"),
                     txt = "Minimum set problem,") 

# render plot
print(p10)
```

## Minimum set benchmark results including high boundary penalty

Now lets look at the same problem types, but this time with a higher
`boundary_penalty` parameter added to the problem formulation.
  
Let's start again with the smallest problem size we've benchmarked.  
This problem has only `r planning_units[1]` planning units. 

```{r "time for pu's 1 and boundary penalty high"}
# make plot
p11 <- benchmark_plot(pus = planning_units[1],
                     bp = boundary_penalty[3],
                     obj = "add_min_set_objective",
                     sol = all_solvers,
                     txt = "Minimum set problem,") 

# render plot
print(p11)
```
  
Next, lets look at the results for a more realistic problem with 
`r planning_units[2]` planning units and see how the timing of the different solvers used
compares.

```{r "time for pu's 2 and boundary penalty high"}
# make plot
p12 <- benchmark_plot(pus = planning_units[2],
                     bp = boundary_penalty[3],
                     obj = "add_min_set_objective",
                     sol = all_solvers,
                     txt = "Minimum set problem,") 

# render plot
print(p12)
```
  
Next, we will look at a medium sized problem with `r planning_units[3]` planning units. Now
we really start to see the difference between SYMPHONY and the other solvers.

```{r "time for pu's 3 and boundary penalty high"}
# make plot
p13 <- benchmark_plot(pus = planning_units[3],
                     bp = boundary_penalty[3],
                     obj = "add_min_set_objective",
                     sol = all_solvers,
                     txt = "Minimum set problem,") 

# render plot
print(p13)
```
  
Finally, lets look at timing comparisons for a large problem with `r planning_units[4]` 
planning units. You can see that the benchmark times vary greatly for the 
SYMPHONY solver.

```{r "time for pu's 4 and boundary penalty high"}
# make plot
p14 <- benchmark_plot(pus = planning_units[4],
                     bp = boundary_penalty[3],
                     obj = "add_min_set_objective",
                     sol = all_solvers,
                     txt = "Minimum set problem,") 

# render plot
print(p14)
```
   
To get a better sense of how the more consistent solvers (CBC, CPLEX, Gurobi) 
compare for this problem size, lets just look at those 3 solvers in the next 
plot.

```{r "time for pu's 4 and boundary penalty high fast"}
# make plot
p15 <- benchmark_plot(pus = planning_units[4],
                     bp = boundary_penalty[3],
                     obj = "add_min_set_objective",
                     sol = c("add_cbc_solver", "add_cplex_solver", 
                             "add_gurobi_solver"),
                     txt = "Minimum set problem,") 

# render plot
print(p15)
```



  
## Minimize shortfall benchmark results

Now, lets investigate the solver behavior in more detail.
Let's start with the smallest problem size we've benchmarked.  
All benchmark scenarios have 72 features.  
This problem has only `r planning_units[1]` planning units. 
You can see that all solvers solve the problem in a comparable amount of time
across all targets investigated. Only the CBC solver takes a little bit longer
then the other ones for the 10% target scenario, but the difference in seconds
is really only ~0.6. 

```{r "min_short time for pu's 1"}
# make plot
p16 <- benchmark_plot(pus = planning_units[1],
                     bp = boundary_penalty[1],
                     obj = "add_min_shortfall_objective",
                     sol = all_solvers,
                     txt = "Minimize shortfall objective,")

# render plot
print(p16)
```
  
Next, lets look at the results for a more realistic problem with 
`r planning_units[2]` planning units and see how the timing of the different solvers used
compares.

```{r "min_short time for pu's 2"}
# make plot
p17 <- benchmark_plot(pus = planning_units[2],
                     bp = boundary_penalty[1],
                     obj = "add_min_shortfall_objective",
                     sol = all_solvers,
                     txt = "Minimize shortfall objective,")
                     

# render plot
print(p17)
```
  
Next, we will look at a medium sized problem with `r planning_units[3]` planning units. Now
we really start to see the difference between SYMPHONY and the other solvers. 

```{r "min_short time for pu's 3"}
# make plot
p18 <- benchmark_plot(pus = planning_units[3],
                     bp = boundary_penalty[1],
                     obj = "add_min_shortfall_objective",
                     sol = all_solvers,
                     txt = "Minimize shortfall objective,")                     

# render plot
print(p18)
```
  
Finally, lets look at timing comparisons for a large problem with `r planning_units[4]` 
planning units. The SYMPHONY solver is really struggling to find solutions now.

```{r "min_short time for pu's 4"}
# make plot
p19 <- benchmark_plot(pus = planning_units[4],
                     bp = boundary_penalty[1],
                     obj = "add_min_shortfall_objective",
                     sol = all_solvers,
                     txt = "Minimize shortfall objective,")                     

# render plot
print(p19)
```
  
To get a better sense of how the faster solvers (CBC, CPLEX, Gurobi) compare for
this problem size, lets just look at those 3 solvers in the next plot.

```{r "min_short time for pu's 4 fast only"}
# make plot
p20 <- benchmark_plot(pus = planning_units[4],
                     bp = boundary_penalty[1],
                     obj = "add_min_shortfall_objective",
                     sol = c("add_cbc_solver", "add_cplex_solver", 
                             "add_gurobi_solver"),
                     txt = "Minimize shortfall objective,") 

# render plot
print(p20)
```


## Minimize shortfall benchmark results including low boundary penalty

Now lets at the same problem types, but this time with a `boundary_penalty` 
parameter added to the problem formulation.
  
Let's start again with the smallest problem size we've benchmarked.  
This problem has only `r planning_units[1]` planning units. 

```{r "min_short time for pu's 1 and boundary penalty"}
# make plot
p21 <- benchmark_plot(pus = planning_units[1],
                     bp = boundary_penalty[4],
                     obj = "add_min_shortfall_objective",
                     sol = all_solvers,
                     txt = "Minimize shortfall objective,") 

# render plot
print(p21)
```
  
Next, lets look at the results for a more realistic problem with 
`r planning_units[2]` planning units and see how the timing of the different solvers used
compares.

```{r "min_short time for pu's 2 and boundary penalty"}
# make plot
p22 <- benchmark_plot(pus = planning_units[2],
                     bp = boundary_penalty[4],
                     obj = "add_min_shortfall_objective",
                     sol = all_solvers,
                     txt = "Minimize shortfall objective,") 

# render plot
print(p22)
```
  
Next, we will look at a medium sized problem with `r planning_units[3]` planning units. Now
we really start to see the difference between SYMPHONY and the other solvers.

```{r "min_short time for pu's 3 and boundary penalty"}
# make plot
p23 <- benchmark_plot(pus = planning_units[3],
                     bp = boundary_penalty[4],
                     obj = "add_min_shortfall_objective",
                     sol = all_solvers,
                     txt = "Minimize shortfall objective,") 

# render plot
print(p23)
```
  
Finally, lets look at timing comparisons for a large problem with `r planning_units[4]` 
planning units. You can see that the benchmark times vary greatly for the 
SYMPHONY solver.

```{r "min_short time for pu's 4 and boundary penalty"}
# make plot
p24 <- benchmark_plot(pus = planning_units[4],
                     bp = boundary_penalty[4],
                     obj = "add_min_shortfall_objective",
                     sol = all_solvers,
                     txt = "Minimize shortfall objective,") 

# render plot
print(p24)
```
   
To get a better sense of how the more consistent solvers (CBC, CPLEX, Gurobi) 
compare for this problem size, lets just look at those 3 solvers in the next 
plot.

```{r "min_short time for pu's 4 and boundary penalty fast"}
# make plot
p25 <- benchmark_plot(pus = planning_units[4],
                     bp = boundary_penalty[4],
                     obj = "add_min_shortfall_objective",
                     sol = c("add_cbc_solver", "add_cplex_solver", 
                             "add_gurobi_solver"),
                     txt = "Minimize shortfall objective,") 

# render plot
print(p25)
```

## Minimize shortfall benchmark results including high boundary penalty

Now lets look at the same problem types, but this time with a higher
`boundary_penalty` parameter added to the problem formulation.
  
Let's start again with the smallest problem size we've benchmarked.  
This problem has only `r planning_units[1]` planning units. 

```{r "min_short time for pu's 1 and boundary penalty high"}
# make plot
p26 <- benchmark_plot(pus = planning_units[1],
                     bp = boundary_penalty[5],
                     obj = "add_min_shortfall_objective",
                     sol = all_solvers,
                     txt = "Minimize shortfall objective,") 

# render plot
print(p26)
```
  
Next, lets look at the results for a more realistic problem with 
`r planning_units[2]` planning units and see how the timing of the different solvers used
compares.

```{r "min_short time for pu's 2 and boundary penalty high"}
# make plot
p27 <- benchmark_plot(pus = planning_units[2],
                     bp = boundary_penalty[5],
                     obj = "add_min_shortfall_objective",
                     sol = all_solvers,
                     txt = "Minimize shortfall objective,") 

# render plot
print(p27)
```
  
Next, we will look at a medium sized problem with `r planning_units[3]` planning units. Now
we really start to see the difference between SYMPHONY and the other solvers.

```{r "min_short time for pu's 3 and boundary penalty high"}
# make plot
p28 <- benchmark_plot(pus = planning_units[3],
                     bp = boundary_penalty[5],
                     obj = "add_min_shortfall_objective",
                     sol = all_solvers,
                     txt = "Minimize shortfall objective,") 

# render plot
print(p28)
```
  
Finally, lets look at timing comparisons for a large problem with `r planning_units[4]` 
planning units. You can see that the benchmark times vary greatly for the 
SYMPHONY solver.

```{r "min_short time for pu's 4 and boundary penalty high"}
# make plot
p29 <- benchmark_plot(pus = planning_units[4],
                     bp = boundary_penalty[5],
                     obj = "add_min_shortfall_objective",
                     sol = all_solvers,
                     txt = "Minimize shortfall objective,") 

# render plot
print(p29)
```
   
To get a better sense of how the more consistent solvers (CBC, CPLEX, Gurobi) 
compare for this problem size, lets just look at those 3 solvers in the next 
plot.

```{r "min_short time for pu's 4 and boundary penalty high fast"}
# make plot
p30 <- benchmark_plot(pus = planning_units[4],
                     bp = boundary_penalty[5],
                     obj = "add_min_shortfall_objective",
                     sol = c("add_cbc_solver", "add_cplex_solver", 
                             "add_gurobi_solver"),
                     txt = "Minimize shortfall objective,") 

# render plot
print(p30)
```

